{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "277dd802-3006-464c-a293-204ea4d5dcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "from pprint import pprint\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "#export 'BEARER_TOKEN'='<your_bearer_token>' >>> initially tried that syntax but didn't work, variables returned none\n",
    "load_dotenv()  # take environment variables from .env.\n",
    "\n",
    "bearer_token = os.environ.get(\"BEARER_TOKEN\")\n",
    "qb_user_token = os.environ.get(\"QB_USER_TOKEN\")\n",
    "\n",
    "#get request arguments query_params, headers and search_url\n",
    "query_params = {\n",
    "    'query': '#QuickBase OR #NoCode OR #LowCode OR #QBCommunitySummit',\n",
    "    # https://developer.twitter.com/en/docs/twitter-api/tweets/search/api-reference \n",
    "    'tweet.fields':'author_id,created_at,entities',\n",
    "    # https://developer.twitter.com/en/docs/twitter-api/users/lookup/api-reference/get-users-by-username-username\n",
    "    'expansions':'author_id',\n",
    "    'user.fields': 'username,id',\n",
    "    #Twitter pagination from 10 to 100\n",
    "    'max_results': 100,\n",
    "}\n",
    "\n",
    "# 2 endpoints available, \"all\" and \"recent\". All is only available for academic and research. I only have access to recent which gives me the most recent 7 days\n",
    "# https://developer.twitter.com/en/docs/twitter-api/tweets/search/api-reference/get-tweets-search-all\n",
    "# https://developer.twitter.com/en/docs/twitter-api/tweets/search/api-reference/get-tweets-search-recent\n",
    "search_url = \"https://api.twitter.com/2/tweets/search/recent\"\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {bearer_token}\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2089030c-5904-41ca-b25f-71b267a55571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#token to request the next page due to Twitter API pagination >> max 100/page min 10/page\n",
    "#https://developer.twitter.com/en/docs/twitter-api/pagination\n",
    "next_token = None\n",
    "\n",
    "#dictionary to map userids to usernames\n",
    "users = {}\n",
    "\n",
    "#list of tweets\n",
    "tweets = []\n",
    "\n",
    "for i in range(5): #looping to get X number of tweets (more than 100)\n",
    "    \n",
    "    # next_token only used starting the second request \n",
    "    if i > 0:\n",
    "        query_params['next_token'] = next_token\n",
    "    \n",
    "    # sending get request to twitter API\n",
    "    response = requests.get(search_url, headers=headers, params=query_params)\n",
    "    page = response.json()\n",
    "    next_token = page['meta']['next_token']\n",
    "    \n",
    "    # upserting usernames to users dictionary\n",
    "    for user in page['includes']['users']:\n",
    "        userid = user['id']\n",
    "        username = user['username']\n",
    "        users[userid] = username\n",
    "        \n",
    "    # Reshaping the twitter data with the proper formatting for the Quickbase API\n",
    "    for tweet in page['data']:\n",
    "        tweet_id = tweet['id']\n",
    "        tweet_text = tweet['text']\n",
    "        tweet_created_at = tweet['created_at']\n",
    "        tweet_author_id = tweet['author_id']\n",
    "        \n",
    "        #extracting tags and exception handling for when no hashtags are returned >> get 'hashtags', [] otherwise \n",
    "        tweet_hashtags = [hashtag['tag'] for hashtag in tweet['entities'].get('hashtags', [])]\n",
    "        \n",
    "        #twitter strips data after 140th character. resulting in incomplete records (in some cases not including the tags we're looking for),\n",
    "        #although the original tweet includes the hashtags, hence them showing in the response in the first place!\n",
    "        \n",
    "        #filtering out records that don't include the tags in the response\n",
    "        if \"nocode\" in tweet_hashtags or 'QuickBase' in tweet_hashtags or 'LowCode' in tweet_hashtags or'QBCommunitySummit' in tweet_hashtags:\n",
    "            tweets.append({\n",
    "                \n",
    "                #'record ID#'\n",
    "                '10': { #'11' for the copy of tweets table in QB\n",
    "                    \"value\": tweet_id\n",
    "                },\n",
    "                \n",
    "                #'Hashtags'\n",
    "                '6': {\n",
    "                    \"value\": tweet_hashtags\n",
    "                },\n",
    "                \n",
    "                #'Twitter_Username'\n",
    "                '7':{\n",
    "                    \"value\": users.get(tweet_author_id, None)\n",
    "                },\n",
    "                \n",
    "                #'Tweet_Content'\n",
    "                '8': {\n",
    "                    \"value\":tweet_text\n",
    "                },\n",
    "                \n",
    "                #'Date'\n",
    "                '9':{\n",
    "                    \"value\": tweet_created_at.split(\"T\")[0] # for date field in QB\n",
    "                    #\"value\": tweet_created_at for date/time field in QB\n",
    "                },\n",
    "            })\n",
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a71c79f-c26e-4f0b-a095-c23f625c8085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('===Notes/DominoÈñãÁô∫tips„ÅÆÊ¶ÇË¶ÅÁ¥π‰ªã===\\n\\n3/25„Å´‰∫àÂëä„Åó„Åü„Å®„Åä„Çä„ÄÅÊú¨Êó•Ôºà3/28ÔºâÂàÜ„ÅÆtips„ÅåÈÖç‰ø°„Åï„Çå„Åæ„Åó„Åü„ÄÇ„ÅäÂÆ¢Êßò„Å´„Åä„Åç„Åæ„Åó„Å¶„ÅØNotes DB„ÅßÂÜÖÂÆπ„Çí„ÅîÁ¢∫Ë™ç„ÅÑ„Åü„Å†„Åë„Åæ„Åô„ÄÇ\\n\\nÈñ¢ÈÄ£„Éñ„É≠„Ç∞„ÅØ‰ª•‰∏ã„ÅÆ„É™„É≥„ÇØ„ÇíÁ¢∫Ë™ç„Åó„Å¶„Åè„Å†„Åï„ÅÑ\\n\\n#tips #dominoforever #„Ç´„É¨„É≥„ÉÄ„Éº #Êó•‰ªò #lowcode\\nhttps://t.co/RTIKDIHkxn',\n",
       "  '1508243824472358912'),\n",
       " ('RT @VeilleCyber3: Artificial intelligence is everywhere now. \\nhttps://t.co/0fTbgb6TUi\\n\\n#AIEthics #MachineLearning #AI #Python #DeepLearning‚Ä¶',\n",
       "  '1508243204558266377'),\n",
       " ('RT @VeilleCyber3: Artificial intelligence is everywhere now. \\nhttps://t.co/0fTbgb6TUi\\n\\n#AIEthics #MachineLearning #AI #Python #DeepLearning‚Ä¶',\n",
       "  '1508241910145564672'),\n",
       " ('RT @hjpatelspace: Check new Updates on our SpaceüöÄ\\n\\nRead Details : https://t.co/K43cJhe49M\\n\\n#HJPatel \\n#100DaysOfCode #WomenWhoCode #python #‚Ä¶',\n",
       "  '1508239939594510338'),\n",
       " ('RT @hjpatelspace: Check new Updates on our SpaceüöÄ\\n\\nRead Details : https://t.co/K43cJhe49M\\n\\n#HJPatel \\n#100DaysOfCode #WomenWhoCode #python #‚Ä¶',\n",
       "  '1508239774255095822'),\n",
       " ('RT @VeilleCyber3: Why #African #banks are investing in #AI \\nhttps://t.co/gxKxxlVdWx\\n\\n#AIEthics #MachineLearning #AI #Python #DeepLearning #‚Ä¶',\n",
       "  '1508237964173844481'),\n",
       " ('RT @NoCodeAdvantage: I was a WANTrepreneur until I discovered #NoCode. I learned @Bubble + built a custom software (in 2 months) that went‚Ä¶',\n",
       "  '1508237783768383490'),\n",
       " (\"But what a disappointment if time on this as yet unknown landing place had also been progressing and our astronauts were not greeted as 'gods', but laughed at as being living far behind the times!\\n\\nChariots Of The Gods? By\\nErich Von Daniken\\n\\nWas God An Astronaut?\\n\\n#occult #nocode https://t.co/NGC9rCECbQ\",\n",
       "  '1508237495271665664'),\n",
       " ('RT @valuepress_cp: Êó•Êú¨ÊúÄÂ§ßÁ¥ö„ÅÆ„Éé„Éº„Ç≥„Éº„ÉâÂ∞ÇÈñÄ„Ç™„É≥„É©„Ç§„É≥„Çµ„É≠„É≥„Åå„ÄÅÂàùÁ¥öÔΩû‰∏äÁ¥öÂêë„Åë„Åæ„ÅßÊßò„ÄÖ„Å™‚ÄúÈÄ£Êó•„Ç§„Éô„É≥„Éà‚Äù„Çí3ÊúàÊúÄÁµÇÈÄ±„ÇÇÂÆüÊñΩÔºÅ #„Éé„Éº„Ç≥„Éº„Éâ #NoCode #„Éó„É≠„Ç∞„É©„Éü„É≥„Ç∞ #„Ç¢„Éó„É™ #„Ç§„Éô„É≥„Éà #„Çª„Éü„Éä„Éº #„Ç™„É≥„É©„Ç§„É≥\\nhttps://t.co/9OzhT‚Ä¶',\n",
       "  '1508235762382544898'),\n",
       " ('RT @buzzycompany: Buzzy @figma Plugin UPDATE released - designed to make it easier to turn your #Figma Designs into real working apps and s‚Ä¶',\n",
       "  '1508235760813629440')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get request arguments query_params, headers and \n",
    "query_params2 = {\n",
    "    'query': '#QuickBase OR #NoCode OR #LowCode OR #QBCommunitySummit',\n",
    "    # https://developer.twitter.com/en/docs/twitter-api/tweets/search/api-reference \n",
    "    'tweet.fields':'author_id,created_at',\n",
    "    # https://developer.twitter.com/en/docs/twitter-api/users/lookup/api-reference/get-users-by-username-username\n",
    "    'expansions':'author_id',\n",
    "    'user.fields': 'username,id',\n",
    "    #Twitter pagination from 10 to 100\n",
    "    'max_results': 10,\n",
    "}\n",
    "\n",
    "# 2 endpoints available, \"all\" and \"recent\". All is only available for academic and research. I only have access to recent which gives me the most recent 7 days\n",
    "# https://developer.twitter.com/en/docs/twitter-api/tweets/search/api-reference/get-tweets-search-all\n",
    "# https://developer.twitter.com/en/docs/twitter-api/tweets/search/api-reference/get-tweets-search-recent\n",
    "search_url2 = \"https://api.twitter.com/2/tweets/search/recent\"\n",
    "\n",
    "headers2 = {\n",
    "    \"Authorization\": f\"Bearer {bearer_token}\"\n",
    "}\n",
    "\n",
    "response = requests.get(search_url2, headers=headers2, params=query_params2).json()\n",
    "\n",
    "#response['data']\n",
    "list(map(lambda x: (x['text'],x['id']), response['data']))\n",
    "\n",
    "\n",
    "##https://twitter.com/i/web/status/1508213112306081809"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7f61d8a-3cc7-4f41-8b4b-53788ef3ccfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#formatting JSON for Quickbase post request\n",
    "body = {\n",
    "    #\"to\": \"br9e6snt2\", #copy of tweets table in QB\n",
    "    \"to\": \"br9btjupe\",\n",
    "    \"data\": tweets,\n",
    "}\n",
    "\n",
    "jsontweets = json.dumps(body)\n",
    "#jsontweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62eaab8a-525c-43ba-8976-b3fd279c60c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': [],\n",
       " 'metadata': {'createdRecordIds': [153,\n",
       "   154,\n",
       "   155,\n",
       "   156,\n",
       "   157,\n",
       "   158,\n",
       "   159,\n",
       "   160,\n",
       "   161,\n",
       "   162,\n",
       "   163,\n",
       "   164,\n",
       "   165,\n",
       "   166,\n",
       "   167,\n",
       "   168,\n",
       "   169,\n",
       "   170,\n",
       "   171,\n",
       "   172,\n",
       "   173,\n",
       "   174,\n",
       "   175,\n",
       "   176,\n",
       "   177,\n",
       "   178,\n",
       "   179,\n",
       "   180,\n",
       "   181,\n",
       "   182,\n",
       "   183,\n",
       "   184,\n",
       "   185,\n",
       "   186,\n",
       "   187,\n",
       "   188,\n",
       "   189,\n",
       "   190,\n",
       "   191,\n",
       "   192,\n",
       "   193,\n",
       "   194,\n",
       "   195,\n",
       "   196,\n",
       "   197,\n",
       "   198,\n",
       "   199,\n",
       "   200,\n",
       "   201,\n",
       "   202,\n",
       "   203,\n",
       "   204,\n",
       "   205,\n",
       "   206,\n",
       "   207,\n",
       "   208,\n",
       "   209,\n",
       "   210,\n",
       "   211,\n",
       "   212,\n",
       "   213,\n",
       "   214,\n",
       "   215,\n",
       "   216,\n",
       "   217,\n",
       "   218,\n",
       "   219,\n",
       "   220,\n",
       "   221,\n",
       "   222,\n",
       "   223,\n",
       "   224,\n",
       "   225,\n",
       "   226,\n",
       "   227,\n",
       "   228,\n",
       "   229,\n",
       "   230,\n",
       "   231,\n",
       "   232,\n",
       "   233,\n",
       "   234,\n",
       "   235,\n",
       "   236,\n",
       "   237,\n",
       "   238,\n",
       "   239,\n",
       "   240,\n",
       "   241,\n",
       "   242,\n",
       "   243,\n",
       "   244,\n",
       "   245,\n",
       "   246,\n",
       "   247,\n",
       "   248,\n",
       "   249,\n",
       "   250,\n",
       "   251,\n",
       "   252,\n",
       "   253,\n",
       "   254,\n",
       "   255,\n",
       "   256,\n",
       "   257],\n",
       "  'totalNumberOfRecordsProcessed': 139,\n",
       "  'unchangedRecordIds': [5,\n",
       "   8,\n",
       "   9,\n",
       "   16,\n",
       "   20,\n",
       "   21,\n",
       "   25,\n",
       "   31,\n",
       "   35,\n",
       "   36,\n",
       "   39,\n",
       "   41,\n",
       "   42,\n",
       "   43,\n",
       "   53,\n",
       "   54,\n",
       "   60,\n",
       "   61,\n",
       "   64,\n",
       "   70,\n",
       "   79,\n",
       "   89,\n",
       "   90,\n",
       "   91,\n",
       "   93,\n",
       "   96,\n",
       "   102,\n",
       "   106,\n",
       "   115,\n",
       "   117,\n",
       "   121,\n",
       "   122,\n",
       "   124,\n",
       "   125],\n",
       "  'updatedRecordIds': []}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qb_headers = {\n",
    "  \t'QB-Realm-Hostname': 'team.quickbase.com',\n",
    "    #same thing here, storing it here while working on the assignment..\n",
    "\t'Authorization': f'QB-USER-TOKEN {qb_user_token}'\n",
    "}\n",
    "\n",
    "r = requests.post(\n",
    "        'https://api.quickbase.com/v1/records', \n",
    "        headers = qb_headers, \n",
    "        json = body\n",
    "    )\n",
    "\n",
    "upload = r.json()\n",
    "upload\n",
    "\n",
    "#https://twitter.com/Youssef60079013/status/1508214468467204096\n",
    "#https://twitter.com/i/web/status/1508216889922752500\n",
    "#tweeted once with all hashtags to test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562bccf3-9fb9-416c-a62f-dc06ccc55150",
   "metadata": {},
   "source": [
    "If I had more time, read/learn more about Unit Testing in python!\n",
    "https://docs.python.org/3/library/unittest.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
